ðŸ“Œ Task 1: Data Preparation
ðŸ”¹ Objective

Prepare the Telco Customer Churn dataset for machine learning by handling missing values, encoding categorical variables, and ensuring data consistency.
ðŸ”¹ Steps Performed

Dataset Upload

Loaded the dataset (Telco_Customer_Churn_Dataset.csv) into Google Colab using Pandas.

Data Exploration

Checked dataset shape, column data types, and summary statistics.

Identified missing values and categorical variables.

Handling Missing Values

Numerical columns: Replaced missing values with the mean.

Categorical columns: Replaced missing values with the mode.

Encoding Categorical Variables

Binary categorical features (Yes/No): Applied Label Encoding (0/1).

Multi-category features: Applied One-Hot Encoding using pd.get_dummies() (drop_first=True to avoid multicollinearity).

Verification

Confirmed no missing values remained.

Verified all features were numeric and dataset was ML-ready.
ðŸ”¹ Tools & Libraries

Python

Pandas

NumPy

Scikit-learn

Google Colab
ðŸ”¹ Skills Practiced

âœ… Data preprocessing techniques
âœ… Handling missing values
âœ… Categorical variable encoding
âœ… Preparing data for ML pipeline

ðŸ”¹ Outcome

The dataset is now clean, consistent, and machine-learning ready, forming the foundation for further tasks like data splitting, feature selection, and model training.

ðŸ“Œ Task 2: Data Splitting
ðŸ”¹ Objective

Split the Telco Customer Churn dataset into training (80%) and testing (20%) sets for fair model training and evaluation, ensuring the split is representative of the target variable distribution.

ðŸ”¹ Steps Performed

Dataset Upload

Loaded the preprocessed dataset (Telco_Customer_Churn_Dataset.csv) into Google Colab.

Feature/Target Separation

Defined features (X) as all columns except Churn.

Defined target (y) as the Churn column.

Train-Test Split

Used scikit-learnâ€™s train_test_split function.

Parameters:

test_size=0.2 â†’ 20% for testing, 80% for training

random_state=42 â†’ ensures reproducibility

stratify=y â†’ maintains class balance of churn vs. non-churn customers

Basic Checks

Verified training/testing set shapes.

Confirmed target variable distribution is preserved in both splits.

ðŸ”¹ Tools & Libraries

Python

Pandas

NumPy

Scikit-learn

Google Colab

ðŸ”¹ Skills Practiced

âœ… Data splitting methodologies
âœ… Understanding training/testing dataset requirements
âœ… Ensuring reproducible and representative splits

ðŸ”¹ Outcome

The dataset was successfully divided into train (80%) and test (20%) sets, ensuring fair model evaluation and avoiding data leakage in future tasks.

ðŸ“Œ Task 3: Feature Selection & Correlation Analysis
ðŸ”¹ Objective

Identify the most influential features contributing to customer churn by applying correlation analysis and domain knowledge.

ðŸ”¹ Steps Performed

Dataset Upload

Loaded the preprocessed dataset (Telco_Customer_Churn_Dataset.csv) into Google Colab.

Feature-Target Correlation

Calculated correlation of all features with the target variable Churn.

Ranked features based on absolute correlation values.

Top Features Selection

Identified Top 10 most influential features affecting churn.

Focused on attributes like tenure, contract type, internet service, monthly charges, etc.

Correlation Heatmap

Created a heatmap visualization of the top 10 features.

Helped in spotting feature relationships and multicollinearity.

Domain Knowledge Validation

Verified feature importance with business understanding.

Example: Short tenure, high monthly charges, and contract type are logically linked to higher churn rates.

ðŸ”¹ Tools & Libraries

Python

Pandas

NumPy

Seaborn

Matplotlib

Scikit-learn

Google Colab

ðŸ”¹ Skills Practiced

âœ… Feature selection techniques
âœ… Correlation analysis
âœ… Visualization with heatmaps
âœ… Applying domain knowledge to validate attributes

ðŸ”¹ Outcome

Identified the Top 10 features influencing customer churn with statistical support and business logic.
This step ensures better model interpretability and improves prediction accuracy by focusing on the most relevant attributes.
